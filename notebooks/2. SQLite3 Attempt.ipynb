{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEng-Team-Project-ML\n",
    "\n",
    "This notebook contains the initial analysis of JSON files generated \\\n",
    "by our ML system as of December 2022 (refer to git commit for exact \\\n",
    "version).\n",
    "\n",
    "Each one of our key objectives is potentially non-trivial to implement. \\\n",
    "The issues with each objective are listed below: \n",
    "- Object Identification \n",
    "  - This objective is the easiest to implement as we have the predicted \\\n",
    "    object along with it's bounding box per frame. However, across different \\\n",
    "    frames the object and camera can experience different scenarios which \\\n",
    "    can make relying on any individual frame invalid. For example, the \\\n",
    "    `00001.01350_2022-12-07T15-35-24.000Z.mp4` test file in the daytime \\\n",
    "    dataset on Google Drive shows the bus which is driving away from the \\\n",
    "    camera as being misidentified as a truck closer towards the middle / \\\n",
    "    end of the video. This is a common theme throughout the TFL JamCam \\\n",
    "    datasets. One way to rectify this, is to take the object predictions across \\\n",
    "    the entire time the object is in view (by taking it's predicted anchor value) \\\n",
    "    and determining the mode of the predicted classes. This is likely to be correct \\\n",
    "    for nice scenarios (day time, no glare). This needs to be deliberated further \\\n",
    "    for harder conditions such as night time / snow, etc.\n",
    "- Object Count\n",
    "  - For this objective, although it may appear simple on the surface, is \\\n",
    "    actually non-trivial because we have to correctly count the number of \\\n",
    "    objects across a time period. This becomes difficult for two reasons, \\\n",
    "    firstly we have to correctly identify the same object moving across \\\n",
    "    the field of view which can be problematic if the object is momentarily \\\n",
    "    obscured for whatever reason (e.g. camera blur, goes out of view and then \\\n",
    "    back into view. For example in our case, an object could cross from one exit \\\n",
    "    onto another exit in the Bunarby Road junction but be blocked by a HGV vehicle. \\\n",
    "    This would now count as a new object which would affect our counting of the objects). \\\n",
    "    The second issue is if the object is momentarily miscategorised which means that \\\n",
    "    yolov7's default method of tracking the object considers it a different object.\n",
    "- Object Tracking\n",
    "  - Similar to the above issue, object tracking relies on being able to identify the object \\\n",
    "    you are tracking as the same object across different frames. If an object is misidentified \\\n",
    "    partially before the video ends or the object exits the frame, this can cause the object \\\n",
    "    tracker to treat the object which was already being tracked as a new object. In theory, \\\n",
    "    we could implement code to see where a route / object was already being tracked and treat \\\n",
    "    it as the same object if it is reasonably close to what was being tracked before. This requires \\\n",
    "    testing / experimenting / tweaking. It is likely we can get a solution which is good enough \\\n",
    "    but I don't think we can straight up solve this issue as it has complex, non-trivial edge cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load COCO Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "COCO_YAML_PATH = \"../yolov7-segmentation/data/coco.yaml\"\n",
    "\n",
    "def load_coco_classes(coco_settings):\n",
    "    with open(coco_settings, \"r\") as stream:\n",
    "        try:\n",
    "            coco_data = yaml.safe_load(stream)\n",
    "            coco_data = coco_data[\"names\"]\n",
    "            return coco_data\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "COCO_CLASSES = load_coco_classes(COCO_YAML_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Saved Analytical Dataset (SQLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28453d1081d3c550fce4dd227bac61cebcdf565b50505afc80cae3c0cf61cf22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
